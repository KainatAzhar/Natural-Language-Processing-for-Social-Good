{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# NLP for Social Good: Toxic Comment Classification\n",
    "\n",
    "### Project Overview\n",
    "This project applies **Natural Language Processing (NLP)** and machine learning to address the critical issue of online toxicity and harassment. It develops a robust classification model capable of automatically identifying and flagging toxic comments on social media platforms. By providing an automated solution, this system can assist human moderators in creating a safer and more inclusive online environment.\n",
    "\n",
    "### Dataset\n",
    "The model is trained on a public dataset from the **Jigsaw Toxic Comment Classification Challenge** on Kaggle. This dataset contains a large number of social media comments with labels for various types of toxicity, including `toxic`, `severe_toxic`, `obscene`, `threat`, `insult`, and `identity_hate`. This rich, real-world dataset makes the project highly relevant and impactful.\n",
    "\n",
    "### Methodology\n",
    "1.  **Data Preprocessing and Cleaning:** The raw text data is cleaned by removing punctuation, stop words, and special characters. The text is then tokenized and converted into a numerical format suitable for a neural network.\n",
    "2.  **Model Architecture:** The project uses a Bidirectional Long Short-Term Memory (**Bi-LSTM**) network. This advanced recurrent neural network can process text sequentially, learning contextual relationships from both forward and backward directions, which is crucial for understanding the nuances of human language.\n",
    "3.  **Training:** The Bi-LSTM model is trained to classify comments into one or more of the toxicity categories. The training process focuses on optimizing the model's ability to accurately identify toxic content while minimizing false positives.\n",
    "4.  **Evaluation:** Model performance is evaluated using key metrics that are essential for imbalanced datasets, such as the **F1-score**, **Precision**, and **Recall**. These metrics provide a more comprehensive view of the model's effectiveness than simple accuracy alone.\n",
    "\n",
    "### Concluded Results\n",
    "The Bi-LSTM model successfully identifies different types of toxic comments with a high F1-score, showcasing its ability to handle a complex, multi-label classification problem. This project demonstrates proficiency in modern NLP techniques, ethical AI application, and the ability to build a practical system to combat a real-world social problem.\n",
    "\n",
    "### Technologies Used\n",
    "- Python\n",
    "- TensorFlow / Keras\n",
    "- Pandas\n",
    "- NumPy\n",
    "- Matplotlib\n",
    "- NLTK\n",
    "- Jupyter Notebook"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "J1r4H1G4B7bO",
    "outputId": "321a4855-4603-490b-d36c-941e737190eb"
   },
   "outputs": [],
   "source": [
    "# Project 12: Toxic Comment Classification\n",
    "\n",
    "# --- Section 1: Setup and Data Loading ---\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional\n",
    "\n",
    "# IMPORTANT: You will need to download the dataset from Kaggle and upload it to your Colab session.\n",
    "# The file is 'train.csv' from the Jigsaw Toxic Comment Classification Challenge.\n",
    "print(\"Loading dataset...\")\n",
    "try:\n",
    "    # Replace 'path/to/train.csv' with the actual path in your session or Google Drive\n",
    "    df = pd.read_csv('train.csv')\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: 'train.csv' not found. Please upload the dataset.\")\n",
    "    # Example of a small synthetic dataset for demonstration if needed\n",
    "    data = {'comment_text': ['This is a great movie.', 'You are an idiot.', 'I love this!', 'Go kill yourself.', 'What a terrible thing to say.'],\n",
    "            'toxic': [0, 1, 0, 1, 1],\n",
    "            'severe_toxic': [0, 0, 0, 1, 0],\n",
    "            'obscene': [0, 0, 0, 0, 0],\n",
    "            'threat': [0, 0, 0, 1, 0],\n",
    "            'insult': [0, 1, 0, 0, 1],\n",
    "            'identity_hate': [0, 0, 0, 0, 0]}\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "print(\"Data head:\")\n",
    "print(df.head())\n",
    "\n",
    "labels = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "\n",
    "# --- Section 2: Data Preprocessing ---\n",
    "print(\"\\nPreprocessing text data...\")\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub('[{}]'.format(re.escape(string.punctuation)), '', text)\n",
    "    return text\n",
    "\n",
    "df['comment_text'] = df['comment_text'].apply(clean_text)\n",
    "\n",
    "X = df['comment_text']\n",
    "y = df[labels]\n",
    "\n",
    "max_words = 20000\n",
    "max_len = 200\n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(X)\n",
    "sequences = tokenizer.texts_to_sequences(X)\n",
    "padded_sequences = pad_sequences(sequences, maxlen=max_len)\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(padded_sequences, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# --- Section 3: Building the Bi-LSTM Model ---\n",
    "print(\"\\nBuilding the Bidirectional LSTM model...\")\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_words, 128, input_length=max_len))\n",
    "model.add(Bidirectional(LSTM(64, return_sequences=True)))\n",
    "model.add(Bidirectional(LSTM(32)))\n",
    "model.add(Dense(len(labels), activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# --- Section 4: Training and Evaluation ---\n",
    "print(\"\\nTraining the model...\")\n",
    "model.fit(X_train, y_train, epochs=5, batch_size=32, validation_split=0.1)\n",
    "\n",
    "print(\"\\nEvaluating the model...\")\n",
    "y_pred_proba = model.predict(X_test)\n",
    "y_pred = (y_pred_proba > 0.5).astype(int)\n",
    "\n",
    "print(\"Classification Report (on Test Data):\")\n",
    "print(classification_report(y_test, y_pred, target_names=labels))\n",
    "\n",
    "print(\"\\nTest Accuracy:\")\n",
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"Overall Test Accuracy: {accuracy*100:.2f}%\")"
   ]
  }
 ]
}
